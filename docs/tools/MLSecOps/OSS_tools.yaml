Tools:
  - name: Advbox
    meta:
      description: "Набор инструментов для генерации целенаправленных примеров, обманывающих нейронные сети, использующие библиотеки PaddlePaddle, PyTorch, Caffe2, MxNet, Keras и TensorFlow. Является утилитой командной строки для генерации примеров без написания кода"
      link_URL: "https://github.com/advboxes/AdvBox"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["Терминал"]
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'Baidu Open Source'
      lic: 'Apache-2.0 license'
  - name: ARX deidentifier
    meta:
      description: "Решение для сокрытия чувствительной информации (персональных данных). В решении используются синтаксические (k-anonymity, ℓ-diversity, t-closeness, δ-presence) и семантические ((ɛ, δ)-differential privacy) модели приватности"
      link_URL: "https://github.com/arx-deidentifier/arx"
      ver_edition: "3.9"
      FSTEK_cert: "Нет"
      redaction: ["3.9.1","3.9.2"]
      RUS_access: "Доступен"
      report_formats: ["Графический интерфейс"]
      detect_metods: ["k-anonymity, ℓ-diversity, t-closeness, δ-presence, (ɛ, δ)-differential privacy"]
      OSS: "true"
      division: "MLSecOps"
      type: ""
      class: ""
      vendor: 'ARX'
      lic: 'Apache-2.0 license'
  - name: Foolbox
    meta:
      description: "Библиотека Python, которая упрощает проведение атак на модели машинного обучения (глубокие нейронные сети). Основана на фреймворке EagerPy и работает с моделями в PyTorch, TensorFlow и JAX."
      link_URL: "https://github.com/bethgelab/foolbox"
      ver_edition: "3.3"
      FSTEK_cert: "Нет"
      redaction: ["3.3.1", "3.3.2", "3.3.3", "3.3.4"]
      RUS_access: "Доступен"
      report_formats: ["Терминал"]
      detect_metods: ["Информация не найдена"]
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Bethgelab'
      lic: 'MIT license'
  - name: PyRIT
    meta:
      description: "Библиотека для оценки LLM‑эндпоинтов на уязвимость к prompt инъекциям и другим рискам, связанным с LLM."
      link_URL: "https://github.com/Azure/PyRIT"
      ver_edition: "0.10.0rc0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: [""]
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Azure'
      lic: 'MIT license'
  - name: Adversarial_ml_ctf
    meta:
      description: "Репозиторий позволяющий развернуть лабораторное задание в рамках CTF. Основная задача - залогиниться на уязвимый веб-сайт путем взлома нейронной модели, вшитой в backend, которая позволяет аутентифицировать пользователей по их изображению."
      link_URL: "https://github.com/arturmiller/adversarial_ml_ctf"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "CTF"
      class: ""
      vendor: 'Artur Miller a.k.a. arturmiller'
      lic: 'Отсутствует'
  - name: AugLy
    meta:
      description: "Библиотека аугментаций данных, поддерживающая аудио, видео, текст и изображения в качестве типов данных. Используется для аугментации данных при обучении моделей, а также оценки пробелов в их устойчивости"
      link_URL: "https://github.com/facebookresearch/AugLy"
      ver_edition: "1.0.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Meta'
      lic: 'Meta custom license'
  - name: Garak
    meta:
      description: "Blackbox сканер уязвимостей для LLM моделей. Комбинирует статические, динамические и адаптивные попытки для отказа нейронных сетей во время диалога с пользователем"
      link_URL: "https://github.com/leondz/garak"
      ver_edition: "0.13"
      FSTEK_cert: "Нет"
      redaction: ["0.13.1", "0.13.2"]
      RUS_access: "Доступен"
      report_formats: ["Терминал"]
      detect_metods: ["Информация не найдена"]
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'NVIDIA'
      lic: 'Apache-2.0 license'
  - name: ModelScan
    meta:
      description: "Инструмент для обнаружения уязвимостей и ошибок, связанных с сериализацией в моделях машинного обучения"
      link_URL: "https://github.com/protectai/modelscan"
      ver_edition: "0.8.7"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'Protect AI'
      lic: 'Apache-2.0 license'
  - name: Raze_to_the_ground_aisec23
    meta:
      description: "Решение, представленное на конференции AISec 2023. Необходимо для создания HTML атак на детекторы фишинговых веб-страниц с использованием моделей машинного обучения"
      link_URL: "https://github.com/advmlphish/raze_to_the_ground_aisec23"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'AdvMLPhish'
      lic: 'Отсутствует'
  - name: Advertorch
    meta:
      description: "Набор Python инструментов для исследований в области устойчивости LLM к атакам . Основные функциональные возможности реализованы в PyTorch."
      link_URL: "https://github.com/BorealisAI/advertorch"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Toolbox"
      class: ""
      vendor: 'RBC Borealis'
      lic: 'LGPL-3.0/GPL-3.0 licenses'
  - name: Awesome-MLSecOps
    meta:
      description: "Список open-source решений, ресурсов и обучающих материалов в области MLSecOps"
      link_URL: "https://github.com/RiccardoBiosas/awesome-MLSecOps"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: ""
      class: ""
      vendor: 'RiccardoBiosas'
      lic: 'MIT license'
  - name: Giskard
    meta:
      description: "Python библиотека, которая автоматически выявляет уязвимости в моделях ИИ — от табличных моделей до LLM, включая ошибки производительности, утечки данных, ложные корреляции, галлюцинации и токсичность"
      link_URL: "https://github.com/Giskard-AI/giskard"
      ver_edition: "2.18"
      FSTEK_cert: "Нет"
      redaction: ["2.18.1"]
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Giskard-AI'
      lic: 'Apache-2.0 license'
  - name: NB Defense
    meta:
      description: "Сканер для Jupyter Notebook, который позволяет обнаруживать секреты и уязвимости (CVE) во импортируемых библиотеках, а также неверные конфигурации в файлах 'ipynb'"
      link_URL: "https://github.com/protectai/nbdefense"
      ver_edition: "1.0.5"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'Protect AI'
      lic: 'Apache-2.0 license'
  - name: Safetensors
    meta:
      description: "Новый формат для сериализации произвольных объектов, разработанный Huggingface. Является альтернативой pickle"
      link_URL: "https://github.com/huggingface/safetensors"
      ver_edition: "0.7.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Serialization method   "
      class: ""
      vendor: 'Huggingface'
      lic: 'Apache-2.0 license'
  - name: Advmlthreatmatrix
    meta:
      description: "База уязвимостей LLM от MITRE organisation. Проект заключается в создании матрицы угроз на ML процессы аналогичной MITRE ATT&CK"
      link_URL: "https://github.com/mitre/advmlthreatmatrix"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Attack matrix"
      class: ""
      vendor: 'MITRE'
      lic: 'Отсутствует'
  - name: CleverHans
    meta:
      description: "Библиотека Python содержащая примеры для построения LLM атак, разработки защиты от них и бенчмаркинга угроз."
      link_URL: "https://github.com/cleverhans-lab/cleverhans"
      ver_edition: "4.0.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'CleverHans lab'
      lic: 'MIT license'
  - name: Knockoffnets
    meta:
      description: "PoC решение созданное для проведения Blackbox атак на генеративные модели с целью кражи данных об их внутреннем строении и используемой семантике"
      link_URL: "https://github.com/tribhuvanesh/knockoffnets"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Data stealing"
      class: ""
      vendor: 'tribhuvanesh'
      lic: 'LGPL-3.0 license'
  - name: Guardrails
    meta:
      description: "Набор инструментов для добавления защитных ограничений (guardrails) в диалоговые LLM системы. Такими ограничениями могут являться защита вывода от нежелательных вопросов (например, политика), предотвращение нарушения предопределенных путей диалога, обработка специфический запросов пользователей и т.д."
      link_URL: "https://github.com/NVIDIA-NeMo/Guardrails"
      ver_edition: "0.19.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "LLM security"
      class: ""
      vendor: 'NVIDIA-NeMo'
      lic: 'NVIDIA custom license'
  - name: Stealing_DL_Models (Copycat CNN)
    meta:
      description: "Репозиторий, в котором подробно рассматривается Copycat CNN - атаки с целью кражи нейросетевых моделей методом черного ящика, не имея доступа ни к весам, ни к обучающим данным. Атака строится на возможности массовой отправки различных изображений модели на обработку с целью их последующего использования для создания датасета и получения копии атакуемой модели"
      link_URL: "https://github.com/jeiks/Stealing_DL_Models"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'Jeiks'
      lic: 'Отсутствует'
  - name: Ai-exploits
    meta:
      description: "Набор практик атак и известных уязвимостей инструментов, фреймворков и библиотек, используемых для построения LLM моделей. Собран специалистами Protect AI и участниками bug-bounty программы 'Huntr'"
      link_URL: "https://github.com/protectai/ai-exploits"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'Protect AI'
      lic: 'Apache-2.0 license'
  - name: DamnVulnerableLLMProject
    meta:
      description: "Уязвимый проект на базе LLM, сделанный для обучения и практики в области безопасности LLM‑систем."
      link_URL: "https://github.com/ReversecLabs/damn-vulnerable-llm-agent"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "CTF"
      class: ""
      vendor: 'Reversec Labs'
      lic: 'Apache-2.0 license'
  - name: LintML
    meta:
      description: "Приложение, использующее статический анализ кода для поиска потенциальных рисков безопасности в проектах машинного обучения"
      link_URL: "https://github.com/JosephTLucas/lintML"
      ver_edition: "0.0.5"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["cli"]
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'JosephTLucas'
      lic: 'GPL-3.0 license'
  - name: OpenAttack
    meta:
      description: "Набор инструментов, написанных на Python, для реализации всего процесса атак путем зломанеренного манипулирования данными (включая предобрабоику текста, доступ к атакуемой модели, генерацию адверсариальных атак и их оценку)"
      link_URL: "https://github.com/thunlp/OpenAttack"
      ver_edition: "2.1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Toolbox"
      class: ""
      vendor: 'Thunlp'
      lic: 'MIT license'
  - name: Tensorflow Model-analysis
    meta:
      description: "Библиотека для проверки моделей, созданных с помощью Tensorflow. Позволяет оценить поведение модели при вводе большого количества данных в случайном порядке"
      link_URL: "https://github.com/tensorflow/model-analysis"
      ver_edition: ""
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Tensorflow'
      lic: 'Apache-2.0 license'
  - name: AiGoat
    meta:
      description: "Специально уязвимая AI инфраструктура, развернутая на AWS, с целью симуляции уязвимостей, описанных в OWASP ML Top 10 "
      link_URL: "https://github.com/orcasecurity-research/AIGoat"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "CTF"
      class: ""
      vendor: 'orcasecurity'
      lic: 'Apache-2.0 license'
  - name: Deep-pwning
    meta:
      description: "легковесный фреймворк для экспериментов с моделями машинного обучения с целью оценки их устойчивости перед потенциальным злоумышленником. В данный момент продукт все еще доводится до ума"
      link_URL: "https://github.com/cchio/deep-pwning"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'Cchio'
      lic: 'MIT license'
  - name: ML_security_study_map
    meta:
      description: "Полноценнный гайд и дорожная карта (roadmap), посвященные развитию навыков и компетенций в области AI security"
      link_URL: "https://github.com/wearetyomsmnv/AI-LLM-ML_security_study_map"
      ver_edition: ""
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'Артем Семенов a.k.a. wearetyomsmnv'
      lic: 'Отсутствует'
  - name: Pallms
    meta:
      description: "Payloads for Attacking Large Language Models или PALLMs - собранный набор полезных нагрузок (payloads) для проведжения атак на  LLM сети"
      link_URL: "https://github.com/mik0w/pallms "
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'Mik0w'
      lic: 'MIT license'
  - name: TensorFlow Privacy
    meta:
      description: "Python библиотека, содержащая оптимизаторы Tensorflow для обучения моделей машинного обучения с использованием подхода дифференциальной приватности. В данный момент библиотека развивается и дорабатывается"
      link_URL: "https://github.com/tensorflow/privacy"
      ver_edition: "0.8.12"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Tensorflow'
      lic: 'Apache-2.0 license'
  - name: AnonLLM
    meta:
      description: "Python пакет, разработанный для анонимизации персональных данных в тексте перед их отправкой в API диалоговых LLM моделей"
      link_URL: "https://github.com/fsndzomga/anonLLM"
      ver_edition: "0.1.10"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Data security"
      class: ""
      vendor: 'Fsndzomga'
      lic: 'Отсутствует'
  - name: Differential-privacy-library
    meta:
      description: "Библиотека от IBM для применения дифференциальной приватности в анализе данных и классическом ML"
      link_URL: "https://github.com/IBM/differential-privacy-library"
      ver_edition: "0.6"
      FSTEK_cert: "Нет"
      redaction: ["0.6.6"]
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'IBM'
      lic: 'MIT license'
  - name: MLSploit
    meta:
      description: "Облачная система, позволяющая исследователям быстро оценивать и сравнивать передовые методы атаки и методы защиты для моделей машинного обучения"
      link_URL: "https://github.com/mlsploit"
      ver_edition: "0.1.3"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["Веб-интерфейс"]
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability management"
      class: ""
      vendor: 'Georgia Tech & Intel'
      lic: 'BSD-3-Clause license'
  - name: Privacy Meter
    meta:
      description: "Библиотека, предназначенная для аудита приватности данных. Инструмент позволяет проводить оценку влияния на защиту данных на основе передовых атак по определению принадлежности к обучающему набору"
      link_URL: "https://github.com/privacytrustlab/ml_privacy_meter"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'privacytrustlab (National university of Singapore)'
      lic: 'MIT license'
  - name: TextAttack
    meta:
      description: "Python‑фреймворк для проведения атак на модели, аугментации данных и обучения моделей в задачах обработки естественного языка (NLP)."
      link_URL: "https://github.com/QData/TextAttack"
      ver_edition: "0.3.10"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["Tty"]
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Framework"
      class: ""
      vendor: 'QData'
      lic: 'MIT license'
  - name: ART(Adversarial-robustness-toolbox)
    meta:
      description: "Python‑библиотека для обеспечения безопасности моделей машинного обучения. Поддерживает все популярные фреймворки машинного обучения (TensorFlow, Keras, PyTorch, scikit-learn, XGBoost, LightGBM, CatBoost, GPy)"
      link_URL: "https://github.com/Trusted-AI/adversarial-robustness-toolbox"
      ver_edition: "1.20"
      FSTEK_cert: "Нет"
      redaction: ["1.20.1"]
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Library"
      class: ""
      vendor: 'Trusted-AI'
      lic: 'MIT license'
  - name: Fml-security
    meta:
      description: "Репозиторий, связанный с докладом «Secure Machine Learning at Scale with MLSecOps». Описывает лучшие практики обеспечения безопасности, применяемые на всех стадиях машинного обучения"
      link_URL: "https://github.com/EthicalML/fml-security"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'EthicalML'
      lic: 'Отсутствует'
  - name: Model-Inversion-Attack-ToolBox
    meta:
      description: "Бенчмарк на Python предназначенный для моделирования инверсивных атак. "
      link_URL: "https://github.com/ffhibnese/Model-Inversionм-Attack-ToolBox"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Benchmark"
      class: ""
      vendor: 'Ffhibnese'
      lic: 'Отсутствует'
  - name: PromptInject
    meta:
      description: "Фреймворк, который модульным образом конструирует промпты, чтобы проводить количественный анализ устойчивости больших языковых моделей (LLM) к атакующим промпт‑атакам"
      link_URL: "https://github.com/agencyenterprise/PromptInject"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Framework"
      class: ""
      vendor: 'AE enterprise'
      lic: 'MIT license'
  - name: TextFooler
    meta:
      description: "Инструмент для проведения адверсариальных атак на текстовые модели (в основном для задач NLP"
      link_URL: "https://github.com/jind11/TextFooler"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Toolbox"
      class: ""
      vendor: 'Di Jin a.k.a. jind11'
      lic: 'MIT license'
  - name: Vger
    meta:
      description: "Консольное приложение для постэксплуатации аутентифицированных инстансов Jupyter с фокусом на атаки в области ИИ/машинного обучения."
      link_URL: "https://github.com/JosephTLucas/vger"
      ver_edition: "0.2.6"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["Терминал"]
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: ""
      class: ""
      vendor: 'JosephTLucas'
      lic: 'GPL-3.0 license'
  - name: Vigil-llm
    meta:
      description: "Совокупность Python библиотеки и REST API для оценки промптов и ответов больших языковых моделей. Позволяет обнаруживать prompt injection, jailbreak‑атак и другие потенциальные угрозы."
      link_URL: "https://github.com/deadbits/vigil-llm"
      ver_edition: "0.10.3"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Vulnerability scanning"
      class: ""
      vendor: 'Deadbits'
      lic: 'Apache-2.0 license'
  - name: Watchtower
    meta:
      description: "Решение для обновления запущенных контейнеров в инфраструктуре путем операции push для нового образа сразу в Docker Hub или локальный registry"
      link_URL: "https://github.com/containrrr/watchtower"
      ver_edition: "1.7.1"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: ""
      class: ""
      vendor: 'containrrr '
      lic: 'Apache-2.0 license'
  - name: Аudit-ai
    meta:
      description: "Python библиотека построенная поверх pandas и sklearn, которая реализует алгоритмы машинного обучения с учетом справедливости (fairness-aware)"
      link_URL: "https://github.com/pymetrics/audit-ai"
      ver_edition: "0.1.1"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: ""
      class: ""
      vendor: 'pymetrics'
      lic: 'MIT license'
  - name: awesome-security-for-ai
    meta:
      description: "Cтруктурированный каталог материалов по безопасности и защите AI/ML‑систем"
      link_URL: "https://github.com/TalEliyahu/Awesome-AI-Security"
      ver_edition: "v1.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: []
      detect_metods: []
      OSS: "true"
      division: "MLSecOps"
      type: "Полезные материалы"
      class: ""
      vendor: 'TalEliyahu'
      lic: 'MIT license'
  - name: Rebuff
    meta:
      description: "Фреймворк для защиты LLM‑приложений от prompt‑инъекций и jailbreak‑атак, включающий фильтры и эвристики для проверки входных и выходных сообщений."
      link_URL: "https://github.com/protectai/rebuff"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Недоступен"
      report_formats: ["JSON", "лог‑формат"]
      detect_metods: ["prompt injection", "jailbreak", "output abuse patterns"]
      OSS: "true"
      division: "MLSecOps"
      type: "LLM prompt security"
      class: ""
      vendor: "Protect AI"
      lic: "Apache-2.0 license"
  - name: NeMo Guardrails
    meta:
      description: "Фреймворк для создания программируемых защитных ограничений (guardrails) вокруг LLM‑приложений, позволяющий фильтровать небезопасные запросы и ответы и ограничивать поведение модели."
      link_URL: "https://github.com/NVIDIA/NeMo-Guardrails"
      ver_edition: "0.19.0"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON логи", "policy‑файлы"]
      detect_metods: ["prompt injection", "jailbreak", "policy violations"]
      OSS: "true"
      division: "MLSecOps"
      type: "Guardrails / Policy enforcement"
      class: ""
      vendor: "NVIDIA"
      lic: "Apache-2.0 license"
  - name: Purple Llama Llama Guard
    meta:
      description: "Модели модерации вводов и выводов LLM для фильтрации токсичного контента, утечек секретов и вредоносных запросов."
      link_URL: "https://github.com/meta-llama/PurpleLlama"
      ver_edition: "Llama Guard 3"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON", "лог‑формат"]
      detect_metods: ["toxicity", "self‑harm", "PII leakage", "dangerous prompts"]
      OSS: "true"
      division: "MLSecOps"
      type: "Content moderation"
      class: ""
      vendor: "Meta"
      lic: "Custom open license"
  - name: Purple Llama Prompt Guard
    meta:
      description: "Компонент Purple Llama для защиты от вредоносных промптов и prompt‑инъекций, анализирующий и нормализующий запросы перед отправкой в модель."
      link_URL: "https://github.com/meta-llama/PurpleLlama"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON", "лог‑формат"]
      detect_metods: ["prompt injection", "indirect prompt attacks", "policy‑breaking requests"]
      OSS: "true"
      division: "MLSecOps"
      type: "Prompt security"
      class: ""
      vendor: "Meta"
      lic: "Custom open license"
  - name: Purple Llama Code Shield
    meta:
      description: "Инструмент фильтрации небезопасного кода при генерации LLM, помечающий потенциально уязвимые фрагменты и использование секретов."
      link_URL: "https://github.com/meta-llama/PurpleLlama"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON", "аннотации коду"]
      detect_metods: ["insecure code patterns", "hardcoded secrets", "опасные API"]
      OSS: "true"
      division: "MLSecOps"
      type: "Secure code generation"
      class: ""
      vendor: "Meta"
      lic: "Custom open license"
  - name: CyberSecEval
    meta:
      description: "Набор open‑source бенчмарков для оценки безопасности LLM, проверяющий устойчивость к prompt‑инъекциям, генерации вредоносного кода, фишингу и другим атакам."
      link_URL: "https://github.com/meta-llama/PurpleLlama/tree/main/CyberSecEval"
      ver_edition: "v3"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON", "табличные отчёты"]
      detect_metods: ["prompt injection", "code abuse", "cyber‑attack patterns"]
      OSS: "true"
      division: "MLSecOps"
      type: "Security benchmarks"
      class: ""
      vendor: "Meta"
      lic: "Custom open license"
  - name: CodeGate
    meta:
      description: "Security‑прокси между IDE и LLM‑сервисами, предотвращающий утечки секретов и анализирующий генерируемый код на небезопасные зависимости и паттерны."
      link_URL: "https://github.com/stacklok/codegate"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON логи", "IDE‑нотификации"]
      detect_metods: ["secret leakage", "insecure dependencies", "insecure code"]
      OSS: "true"
      division: "MLSecOps"
      type: "LLM dev security / proxy"
      class: ""
      vendor: "Stacklok"
      lic: "Apache-2.0 license"
  - name: Sigstore (cosign для ML)
    meta:
      description: "Набор инструментов для подписи и валидации контейнеров, артефактов и моделей (через cosign и др.), уменьшающий риски атак на цепочку поставок ML."
      link_URL: "https://www.sigstore.dev"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["подписи и метаданные", "JSON"]
      detect_metods: ["supply‑chain integrity", "signature verification"]
      OSS: "true"
      division: "MLSecOps"
      type: "Supply chain security"
      class: ""
      vendor: "Sigstore / OpenSSF"
      lic: "Apache-2.0 license"
  - name: OpenSSF Scorecard
    meta:
      description: "Инструмент автоматизированной оценки безопасности репозиториев, применимый к ML/MLOps‑проектам для проверки практик разработки и цепочки поставок."
      link_URL: "https://github.com/ossf/scorecard"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["JSON", "SARIF", "табличный отчёт"]
      detect_metods: ["branch protection", "CI security", "dependency management", "signed releases"]
      OSS: "true"
      division: "MLSecOps"
      type: "Repo & supply‑chain audit"
      class: ""
      vendor: "OpenSSF"
      lic: "Apache-2.0 license"
  - name: Metaflow
    meta:
      description: "Фреймворк для построения MLOps‑конвейеров, обеспечивающий трассировку шагов и версионирование артефактов и рекомендуемый в гайдлайнах по безопасной ML‑цепочке поставок."
      link_URL: "https://github.com/Netflix/metaflow"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["логи и метаданные", "JSON API"]
      detect_metods: ["прослеживаемость пайплайнов", "контроль артефактов"]
      OSS: "true"
      division: "MLSecOps"
      type: "Secure MLOps orchestration"
      class: ""
      vendor: "Netflix / Outerbounds"
      lic: "Apache-2.0 license"
  - name: AIShield Watchtower
    meta:
      description: "Инструмент для анализа уязвимостей моделей ИИ: оценивает устойчивость к адверсариальным примерам, атакам извлечения модели и отравлению данных."
      link_URL: "https://github.com/AIShield/Watchtower"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Ограничен"
      report_formats: ["JSON", "логи", "визуальные отчёты"]
      detect_metods: ["adversarial robustness", "model extraction", "poisoning"]
      OSS: "true"
      division: "MLSecOps"
      type: "Model vulnerability scanning"
      class: ""
      vendor: "AIShield"
      lic: "Apache-2.0 license"
  - name: Vigil
    meta:
      description: "Python‑библиотека и REST API для тестирования и мониторинга моделей на предмет устойчивости, утечек данных и других рисков безопасности."
      link_URL: "https://github.com/protectai/vigil"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Недоступен"
      report_formats: ["JSON", "лог‑формат"]
      detect_metods: ["robustness checks", "privacy leakage tests", "consistency checks"]
      OSS: "true"
      division: "MLSecOps"
      type: "Model evaluation / monitoring"
      class: ""
      vendor: "Protect AI"
      lic: "Apache-2.0 license"
  - name: LLAMATOR
    meta:
      description: "Фреймворк для тестирования и укрепления LLM‑систем, включающий сценарии атак и проверки устойчивости, с возможностью интеграции в MLOps‑конвейер."
      link_URL: "https://github.com/llamator-project"
      ver_edition: "Информация не найдена"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["JSON", "табличные отчёты"]
      detect_metods: ["prompt injection", "data leakage", "robustness checks"]
      OSS: "true"
      division: "MLSecOps"
      type: "LLM security / testing"
      class: ""
      vendor: "Сообщество"
      lic: "Различные OSS‑лицензии по модулям"
  - name: ModelScan (расширенный профиль)
    meta:
      description: "CLI‑утилита для сканирования моделей и артефактов (pickle, ONNX и др.) на вредоносный или небезопасный код, применяемая для защиты ML‑цепочки поставок."
      link_URL: "https://github.com/protectai/modelscan"
      ver_edition: "0.8.7"
      FSTEK_cert: "Нет"
      redaction: []
      RUS_access: "Доступен"
      report_formats: ["JSON", "CLI вывод"]
      detect_metods: ["model malware detection", "insecure deserialization", "supply‑chain issues"]
      OSS: "true"
      division: "MLSecOps"
      type: "Model artifact scanning"
      class: ""
      vendor: "Protect AI"
      lic: "Apache-2.0 license"
